{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783bba2d-5346-4563-9e7a-7c42159efd33",
   "metadata": {},
   "source": [
    "# Thesis demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da8909c1-4cef-4ca5-8cab-1fb2823d264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd, json, csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import requests\n",
    "from tenacity import retry\n",
    "\n",
    "from projects_secretes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84465431-d859-40f1-a102-61bfccbfe9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for disabling global var lookup for functions\n",
    "# https://gist.github.com/ax3l/59d92c6e1edefcef85ac2540eb056da3\n",
    "import types\n",
    "from itertools import islice\n",
    "\n",
    "def imports():\n",
    "    for name, val in globals().items():            \n",
    "        # module imports\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield name, val\n",
    "        # functions / callables\n",
    "        if hasattr(val, '__call__'):\n",
    "            yield name, val\n",
    "\n",
    "noglobal = lambda fn: types.FunctionType(fn.__code__, dict(imports()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafac45c-5726-434c-bdcd-990f75f8952d",
   "metadata": {},
   "source": [
    "## Get/update data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34ea5c54-bb62-43bd-8343-ccca4366875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files name\n",
    "@noglobal\n",
    "def get_time_from_fileName(fileName):\n",
    "    dateName = fileName.split(\"/\")[-1][:-5]\n",
    "    date, siteName = dateName.split(\"_\")\n",
    "\n",
    "    return (date, siteName)\n",
    "\n",
    "@noglobal\n",
    "def get_news_fileNames(bucket_name, prefix):\n",
    "    # list all files\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Initialize the paginator\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "    \n",
    "    # Iterate through each page of objects\n",
    "    fileNames = []\n",
    "    for page in page_iterator:\n",
    "        if \"Contents\" in page:  # Check if the page contains objects\n",
    "            for obj in page['Contents']:\n",
    "                if obj['Key'].endswith(\".json\"):\n",
    "                    fileNames.append(obj['Key'])\n",
    "\n",
    "    # filter to exclude already updated data\n",
    "    return fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8dc40cb6-9155-4ca2-903f-fde10b7d4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_bucket_name = \"news-collection-2024-3371\"\n",
    "domestic_fnames = get_news_fileNames(domestic_bucket_name, prefix = \"current_data\")\n",
    "\n",
    "international_bucket_name = 'international-news-collection-2024-2251'\n",
    "international_fnames = get_news_fileNames(international_bucket_name, prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7d789c59-d9ed-485b-ba2b-cb0b4f0e95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get data\n",
    "@noglobal\n",
    "def read_news_file(filekey, bucket):\n",
    "    s3 = boto3.resource('s3')\n",
    "    content = s3.Object(bucket, filekey).get()['Body'].read()\n",
    "\n",
    "    # get date and site name\n",
    "    date, siteName = get_time_from_fileName(filekey)\n",
    "\n",
    "    #  read headline, url, probability and time into a list\n",
    "    content = json.loads(content)\n",
    "    if \"articles\" in content:\n",
    "        result = []\n",
    "\n",
    "        for x in content[\"articles\"]:\n",
    "            row = {}\n",
    "            row[\"url\"] = x.get(\"url\")\n",
    "            row[\"headline\"] = x.get(\"headline\")\n",
    "            row[\"datePublished_site\"] = x.get(\"datePublished\")\n",
    "            row[\"probability\"] = x[\"metadata\"][\"probability\"]\n",
    "    \n",
    "            row[\"date_collected\"] = date\n",
    "            row[\"siteName\"] = siteName\n",
    "            result.append(row)\n",
    "\n",
    "        return (True, result)\n",
    "    else:\n",
    "        # failed collection\n",
    "        return (False, filekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71aad76d-de6c-4223-87fd-76058c6829b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal\n",
    "def read_files_in_parallel(bucketName, fnames):\n",
    "    # Use ThreadPoolExecutor read files in parallel\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        read_news_file_with_partial = partial(read_news_file, bucket=bucketName)\n",
    "        news_headlines = list(tqdm(executor.map(read_news_file_with_partial, fnames), total=len(fnames)))\n",
    "\n",
    "    return news_headlines\n",
    "\n",
    "@noglobal\n",
    "def post_processsing(result):\n",
    "    # post_processsing to create a list of failed collection\n",
    "    processed_result = []\n",
    "    failed_sites = []\n",
    "    for x in result:\n",
    "        if x[0]:\n",
    "            processed_result.append(x[1])\n",
    "        else:\n",
    "            failed_sites.append(x[1])\n",
    "\n",
    "    processed_result = list(chain.from_iterable(processed_result))\n",
    "    return (processed_result, failed_sites)\n",
    "\n",
    "news_headlines_domestic, failed_collection_domestic = post_processsing(read_files_in_parallel(domestic_bucket_name, domestic_fnames))\n",
    "news_headlines_international, failed_collection_international = post_processsing(read_files_in_parallel(international_bucket_name, international_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "46b22745-3e4e-4e18-b36e-9a587b03280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domestic_news = pd.DataFrame(news_headlines_domestic)\n",
    "df_domestic_news.to_parquet('data/data_domestic_news.parquet', index=False)\n",
    "\n",
    "df_international_news = pd.DataFrame(news_headlines_international)\n",
    "df_international_news.to_parquet('data/data_international_news.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d3bafc0a-be8b-417d-bc1f-51b4164c5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the list to a CSV filed\n",
    "\n",
    "def save_to_csv(list, path):\n",
    "    with open(path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Writing each item in the list as a row\n",
    "        for item in list:\n",
    "            writer.writerow([item])\n",
    "\n",
    "save_to_csv(failed_collection_domestic, \"data/failed_collection_domestic.csv\")\n",
    "save_to_csv(failed_collection_international, \"data/failed_collection_international.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee17f7e-7044-42b5-a2fa-132862297964",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e565293b-e23d-4024-83e3-46eadf60685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domestic_news = pd.read_parquet('data/data_domestic_news.parquet')\n",
    "df_international_news = pd.read_parquet('data/data_international_news.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657f4758-c724-4bb4-8568-7840145d5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data cleaning\n",
    "df_domestic_news = df_domestic_news[~df_domestic_news['headline'].isna()] # remove na\n",
    "df_domestic_news = df_domestic_news[df_domestic_news[\"headline\"].apply(lambda headline: len(headline.split(\" \")) >= 3)] # remove very short headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3da3dd-7581-4fd9-9347-6db6278ebabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156538"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_domestic_news[\"headline\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5dbba-5d2b-4fc3-8dcf-88852e954534",
   "metadata": {},
   "source": [
    "There are 156208 unique headlines in the first month of data colleciton, about 100 per day per site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b86b4b-5258-49dd-9f30-80a413cd1658",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed18d61-add2-4bb6-bb5a-2d06e8cca8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8991165\n",
    "# https://huggingface.co/dslim/bert-base-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4c1b456-7606-44f1-9bfa-816906762354",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry\n",
    "def get_NER(payload, url):\n",
    "    headers = {\"Accept\" : \"application/json\", \"Content-Type\": \"application/json\" }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=payload, timeout = 10)\n",
    "    if \"error\" in response.json():\n",
    "        # error response\n",
    "        print(\"error\")\n",
    "        raise exception\n",
    "    else:\n",
    "        return {\"Headline\" : payload[\"inputs\"], \"NER\" : response.json()}\n",
    "\n",
    "def get_NER_in_parllel(url, lines, parameters, maxworkers):\n",
    "    # zip with parameters\n",
    "    lines = [{\"inputs\": line, \"parameters\": parameters} for line in lines]\n",
    "    \n",
    "    # Use ThreadPoolExecutor read files in parallel\n",
    "    with ThreadPoolExecutor(max_workers=maxworkers) as executor:\n",
    "        get_NER_partial = partial(get_NER, url=url)\n",
    "        news_headlines = list(tqdm(executor.map(get_NER_partial, lines), total=len(lines)))\n",
    "\n",
    "    return news_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63f1251b-5c26-4a01-a9d9-0d6ec0f3e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:26<00:00, 48.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:24<00:00, 48.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:25<00:00, 48.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6537/6537 [02:15<00:00, 48.16it/s]\n"
     ]
    }
   ],
   "source": [
    "NER_lines = df_domestic_news[\"headline\"].unique()\n",
    "parameters = {\"aggregation_strategy\": \"simple\"} # perserve different tags\n",
    "\n",
    "cur_index = 0\n",
    "step = 10000\n",
    "while cur_index < len(NER_lines):\n",
    "    NER_lines_seg = NER_lines[cur_index : cur_index + step]\n",
    "    NER_result = get_NER_in_parllel(NER_URL, NER_lines_seg, parameters, 8)\n",
    "\n",
    "    # save file\n",
    "    NER_filename = f'./data/NERs/headline_NER_{int(cur_index / step)}.json'\n",
    "    \n",
    "    # Write to a JSON file\n",
    "    with open(NER_filename, 'w') as file:\n",
    "        json.dump(NER_result, file)\n",
    "        \n",
    "    cur_index += step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8cfa4-3650-43f7-99b7-8bcbc330d015",
   "metadata": {},
   "source": [
    "## SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bbfa8-0eb3-4e11-8e41-2a671d900275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
